{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd4908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "import torch\n",
    "\n",
    "model_id = \"tiiuae/falcon-180B-chat\"\n",
    "# ou para hardware mais modesto: --> model_id = \"tiiuae/falcon-40B-instruct\"\n",
    "\n",
    "token = \"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\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=token)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    token=token,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True  # ✅ Necessário para Falcon\n",
    ")\n",
    "\n",
    "topic = \"artificial intelligence in education\"\n",
    "n_tweets = 30\n",
    "\n",
    "# ✅ Prompt específico para Falcon (formato diferente)\n",
    "prompt = f\"\"\"<|system|>You are a viral social media expert. Generate engaging, human-like tweets. Respond only with tweet texts separated by new lines.<|end|>\n",
    "<|user|>Generate {n_tweets} different tweets about '{topic}'. Each must be under 280 characters, sound natural, and be varied in style. No numbering or bullet points.<|end|>\n",
    "<|assistant|>\"\"\"\n",
    "\n",
    "outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=500,\n",
    "    do_sample=True,\n",
    "    temperature=0.8,\n",
    "    top_p=0.9,\n",
    "    top_k=50,\n",
    "    repetition_penalty=1.2,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "print(outputs[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
