{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00cc316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append('/home/tammy.kojima/Authorship-attribution/')\n",
    "import feature_extraction as fe\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4567bd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>origin</th>\n",
       "      <th>lexical_type_token_ratio</th>\n",
       "      <th>lexical_word_count</th>\n",
       "      <th>lexical_unique_words</th>\n",
       "      <th>lexical_avg_word_length</th>\n",
       "      <th>lexical_word_length_variance</th>\n",
       "      <th>lexical_stopword_ratio</th>\n",
       "      <th>stylistic_random_uppercase</th>\n",
       "      <th>stylistic_repeated_chars</th>\n",
       "      <th>...</th>\n",
       "      <th>complexity_long_sentences</th>\n",
       "      <th>complexity_rare_words</th>\n",
       "      <th>complexity_syntactic_depth</th>\n",
       "      <th>temporal_recent_ratio</th>\n",
       "      <th>temporal_past_ratio</th>\n",
       "      <th>temporal_future_ratio</th>\n",
       "      <th>llm_chatgpt_patterns</th>\n",
       "      <th>llm_structured_output</th>\n",
       "      <th>llm_overly_polite</th>\n",
       "      <th>llm_disclaimer_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our rules are the most robust, the president c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>5.294118</td>\n",
       "      <td>6.442907</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>...associating outsiders with danger and extre...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...alarms were raised in the initial stages of...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>4.968750</td>\n",
       "      <td>4.655273</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The opposition] utilizes every tool to questi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>5.409091</td>\n",
       "      <td>8.787190</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The governor's] fixation with health protocol...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>6.153846</td>\n",
       "      <td>7.207101</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 350 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  origin  \\\n",
       "0  Our rules are the most robust, the president c...       1   \n",
       "1  ...associating outsiders with danger and extre...       1   \n",
       "2  ...alarms were raised in the initial stages of...       1   \n",
       "3  [The opposition] utilizes every tool to questi...       1   \n",
       "4  [The governor's] fixation with health protocol...       1   \n",
       "\n",
       "   lexical_type_token_ratio  lexical_word_count  lexical_unique_words  \\\n",
       "0                  0.882353                  17                    15   \n",
       "1                  1.000000                  18                    18   \n",
       "2                  0.937500                  32                    30   \n",
       "3                  0.727273                  22                    16   \n",
       "4                  0.923077                  13                    12   \n",
       "\n",
       "   lexical_avg_word_length  lexical_word_length_variance  \\\n",
       "0                 5.294118                      6.442907   \n",
       "1                 6.000000                      9.000000   \n",
       "2                 4.968750                      4.655273   \n",
       "3                 5.409091                      8.787190   \n",
       "4                 6.153846                      7.207101   \n",
       "\n",
       "   lexical_stopword_ratio  stylistic_random_uppercase  \\\n",
       "0                0.411765                           0   \n",
       "1                0.277778                           0   \n",
       "2                0.437500                           0   \n",
       "3                0.500000                           0   \n",
       "4                0.384615                           0   \n",
       "\n",
       "   stylistic_repeated_chars  ...  complexity_long_sentences  \\\n",
       "0                         0  ...                        1.0   \n",
       "1                         1  ...                        0.0   \n",
       "2                         1  ...                        1.0   \n",
       "3                         0  ...                        1.0   \n",
       "4                         0  ...                        1.0   \n",
       "\n",
       "   complexity_rare_words  complexity_syntactic_depth  temporal_recent_ratio  \\\n",
       "0               0.764706                    1.500000                    0.0   \n",
       "1               0.777778                    1.750000                    0.0   \n",
       "2               0.812500                    2.857143                    0.0   \n",
       "3               0.590909                    2.166667                    0.0   \n",
       "4               0.769231                    1.333333                    0.0   \n",
       "\n",
       "   temporal_past_ratio  temporal_future_ratio  llm_chatgpt_patterns  \\\n",
       "0                  0.0                    0.0                   0.0   \n",
       "1                  0.0                    0.0                   0.0   \n",
       "2                  0.0                    0.0                   0.0   \n",
       "3                  0.0                    0.0                   0.0   \n",
       "4                  0.0                    0.0                   0.0   \n",
       "\n",
       "   llm_structured_output  llm_overly_polite  llm_disclaimer_density  \n",
       "0                    0.0                0.0                     0.0  \n",
       "1                    0.0                0.0                     0.0  \n",
       "2                    0.0                0.0                     0.0  \n",
       "3                    0.0                0.0                     0.0  \n",
       "4                    0.0                0.0                     0.0  \n",
       "\n",
       "[5 rows x 350 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/tammy.kojima/Authorship-attribution/df_pronto/df_gpt_com_features.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e75cd447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>origin</th>\n",
       "      <th>lexical_type_token_ratio</th>\n",
       "      <th>lexical_word_count</th>\n",
       "      <th>lexical_unique_words</th>\n",
       "      <th>lexical_avg_word_length</th>\n",
       "      <th>lexical_word_length_variance</th>\n",
       "      <th>lexical_stopword_ratio</th>\n",
       "      <th>stylistic_random_uppercase</th>\n",
       "      <th>stylistic_repeated_chars</th>\n",
       "      <th>...</th>\n",
       "      <th>with the</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>you</th>\n",
       "      <th>you are</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our rules are the most robust, the president c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>5.294118</td>\n",
       "      <td>6.442907</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>...associating outsiders with danger and extre...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...alarms were raised in the initial stages of...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>4.968750</td>\n",
       "      <td>4.655273</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The opposition] utilizes every tool to questi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>5.409091</td>\n",
       "      <td>8.787190</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The governor's] fixation with health protocol...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>6.153846</td>\n",
       "      <td>7.207101</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 334 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  origin  \\\n",
       "0  Our rules are the most robust, the president c...       1   \n",
       "1  ...associating outsiders with danger and extre...       1   \n",
       "2  ...alarms were raised in the initial stages of...       1   \n",
       "3  [The opposition] utilizes every tool to questi...       1   \n",
       "4  [The governor's] fixation with health protocol...       1   \n",
       "\n",
       "   lexical_type_token_ratio  lexical_word_count  lexical_unique_words  \\\n",
       "0                  0.882353                  17                    15   \n",
       "1                  1.000000                  18                    18   \n",
       "2                  0.937500                  32                    30   \n",
       "3                  0.727273                  22                    16   \n",
       "4                  0.923077                  13                    12   \n",
       "\n",
       "   lexical_avg_word_length  lexical_word_length_variance  \\\n",
       "0                 5.294118                      6.442907   \n",
       "1                 6.000000                      9.000000   \n",
       "2                 4.968750                      4.655273   \n",
       "3                 5.409091                      8.787190   \n",
       "4                 6.153846                      7.207101   \n",
       "\n",
       "   lexical_stopword_ratio  stylistic_random_uppercase  \\\n",
       "0                0.411765                           0   \n",
       "1                0.277778                           0   \n",
       "2                0.437500                           0   \n",
       "3                0.500000                           0   \n",
       "4                0.384615                           0   \n",
       "\n",
       "   stylistic_repeated_chars  ...  with the  work  working  world  would  year  \\\n",
       "0                         0  ...         0     0        0      0      0     0   \n",
       "1                         1  ...         0     0        0      0      0     0   \n",
       "2                         1  ...         0     0        0      0      0     0   \n",
       "3                         0  ...         0     0        0      0      0     0   \n",
       "4                         0  ...         0     0        0      0      0     0   \n",
       "\n",
       "   years  you  you are  your  \n",
       "0      0    0        0     0  \n",
       "1      0    0        0     0  \n",
       "2      0    0        0     0  \n",
       "3      0    0        0     0  \n",
       "4      0    0        0     0  \n",
       "\n",
       "[5 rows x 334 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=[\"ai_perplexity_score\", \"ai_repeated_ngrams\", \"llm_chatgpt_patterns\", \"llm_structured_output\", \"llm_overly_polite\", \"llm_disclaimer_density\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30a4c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>origin</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our rules are the most robust, the president c...</td>\n",
       "      <td>AI</td>\n",
       "      <td>chat gpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>...associating outsiders with danger and extre...</td>\n",
       "      <td>AI</td>\n",
       "      <td>chat gpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...alarms were raised in the initial stages of...</td>\n",
       "      <td>AI</td>\n",
       "      <td>chat gpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The opposition] utilizes every tool to questi...</td>\n",
       "      <td>AI</td>\n",
       "      <td>chat gpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The governor's] fixation with health protocol...</td>\n",
       "      <td>AI</td>\n",
       "      <td>chat gpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>modi took revenge you bcos you are advani team...</td>\n",
       "      <td>human</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>really doubt any organisation allowed function...</td>\n",
       "      <td>human</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>⃣ already possession this capabilities but thi...</td>\n",
       "      <td>human</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>although nasa doesnt have space suits for wome...</td>\n",
       "      <td>human</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>modi one side and the other side its like comp...</td>\n",
       "      <td>human</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text origin     model\n",
       "0       Our rules are the most robust, the president c...     AI  chat gpt\n",
       "1       ...associating outsiders with danger and extre...     AI  chat gpt\n",
       "2       ...alarms were raised in the initial stages of...     AI  chat gpt\n",
       "3       [The opposition] utilizes every tool to questi...     AI  chat gpt\n",
       "4       [The governor's] fixation with health protocol...     AI  chat gpt\n",
       "...                                                   ...    ...       ...\n",
       "199995  modi took revenge you bcos you are advani team...  human       NaN\n",
       "199996  really doubt any organisation allowed function...  human       NaN\n",
       "199997  ⃣ already possession this capabilities but thi...  human       NaN\n",
       "199998  although nasa doesnt have space suits for wome...  human       NaN\n",
       "199999  modi one side and the other side its like comp...  human       NaN\n",
       "\n",
       "[200000 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt = pd.read_csv('df_pronto/df_gpt.csv')\n",
    "df_human = pd.read_csv('df_pronto/df_human.csv')\n",
    "#df_gpt = df_gpt.iloc[:10000]\n",
    "df_human = df_human.iloc[:100000]\n",
    "df_test = pd.concat([df_gpt, df_human], ignore_index=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "672e2f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Selecionar a coluna de textos\n",
    "# (substitua 'texto' pelo nome real da coluna com o conteúdo)\n",
    "textos = df_test[\"text\"].fillna(\"\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ba12e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizando textos: 100%|██████████| 200000/200000 [36:52<00:00, 90.38it/s] \n",
      "Extraindo features estilísticas: 100%|██████████| 200000/200000 [00:09<00:00, 21115.84it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stylistic_random_uppercase</th>\n",
       "      <th>stylistic_repeated_chars</th>\n",
       "      <th>stylistic_repeated_words</th>\n",
       "      <th>stylistic_exclamation_density</th>\n",
       "      <th>stylistic_question_density</th>\n",
       "      <th>stylistic_ellipsis_count</th>\n",
       "      <th>stylistic_emoji_density</th>\n",
       "      <th>stylistic_emoticon_density</th>\n",
       "      <th>stylistic_capitalization_inconsistency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stylistic_random_uppercase  stylistic_repeated_chars  \\\n",
       "0                           0                         0   \n",
       "1                           0                         1   \n",
       "2                           0                         1   \n",
       "3                           0                         0   \n",
       "4                           0                         0   \n",
       "\n",
       "   stylistic_repeated_words  stylistic_exclamation_density  \\\n",
       "0                         0                            0.0   \n",
       "1                         0                            0.0   \n",
       "2                         0                            0.0   \n",
       "3                         0                            0.0   \n",
       "4                         0                            0.0   \n",
       "\n",
       "   stylistic_question_density  stylistic_ellipsis_count  \\\n",
       "0                         0.0                         0   \n",
       "1                         0.0                         1   \n",
       "2                         0.0                         1   \n",
       "3                         0.0                         0   \n",
       "4                         0.0                         0   \n",
       "\n",
       "   stylistic_emoji_density  stylistic_emoticon_density  \\\n",
       "0                      0.0                         0.0   \n",
       "1                      0.0                         0.0   \n",
       "2                      0.0                         0.0   \n",
       "3                      0.0                         0.0   \n",
       "4                      0.0                         0.0   \n",
       "\n",
       "   stylistic_capitalization_inconsistency  \n",
       "0                                0.000000  \n",
       "1                                0.055556  \n",
       "2                                0.000000  \n",
       "3                                0.000000  \n",
       "4                                0.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokeniza todos os textos primeiro\n",
    "processed_texts = [fe.preprocess_text(texto) for texto in tqdm(textos, desc=\"Tokenizando textos\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc8a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prossessed_texts = pd.DataFrame({'text': processed_texts})\n",
    "df_prossessed_texts.to_csv('df_pronto/df_tokens_gpt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badf2411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [37:08<00:00, 89.73it/s]  \n"
     ]
    }
   ],
   "source": [
    "# Lista para armazenar resultados\n",
    "lexical_features = []\n",
    "\n",
    "for texto in tqdm(textos):\n",
    "    # Tokeniza o texto usando Twokenizer\n",
    "    words = fe.preprocess_text(texto)  # já retorna tokens em lowercase\n",
    "    \n",
    "    # Extrai features léxicas\n",
    "    features = fe.extract_lexical_features(texto, words)\n",
    "    lexical_features.append(features)\n",
    "\n",
    "df_lexical = pd.DataFrame(lexical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b23d0af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>origin</th>\n",
       "      <th>model</th>\n",
       "      <th>lexical_type_token_ratio</th>\n",
       "      <th>lexical_word_count</th>\n",
       "      <th>lexical_unique_words</th>\n",
       "      <th>lexical_avg_word_length</th>\n",
       "      <th>lexical_word_length_variance</th>\n",
       "      <th>lexical_stopword_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our rules are the most robust, the president c...</td>\n",
       "      <td>AI</td>\n",
       "      <td>chat gpt</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>5.294118</td>\n",
       "      <td>6.442907</td>\n",
       "      <td>0.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>...associating outsiders with danger and extre...</td>\n",
       "      <td>AI</td>\n",
       "      <td>chat gpt</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...alarms were raised in the initial stages of...</td>\n",
       "      <td>AI</td>\n",
       "      <td>chat gpt</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>4.968750</td>\n",
       "      <td>4.655273</td>\n",
       "      <td>0.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The opposition] utilizes every tool to questi...</td>\n",
       "      <td>AI</td>\n",
       "      <td>chat gpt</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>5.409091</td>\n",
       "      <td>8.787190</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The governor's] fixation with health protocol...</td>\n",
       "      <td>AI</td>\n",
       "      <td>chat gpt</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>6.153846</td>\n",
       "      <td>7.207101</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text origin     model  \\\n",
       "0  Our rules are the most robust, the president c...     AI  chat gpt   \n",
       "1  ...associating outsiders with danger and extre...     AI  chat gpt   \n",
       "2  ...alarms were raised in the initial stages of...     AI  chat gpt   \n",
       "3  [The opposition] utilizes every tool to questi...     AI  chat gpt   \n",
       "4  [The governor's] fixation with health protocol...     AI  chat gpt   \n",
       "\n",
       "   lexical_type_token_ratio  lexical_word_count  lexical_unique_words  \\\n",
       "0                  0.882353                  17                    15   \n",
       "1                  1.000000                  18                    18   \n",
       "2                  0.937500                  32                    30   \n",
       "3                  0.727273                  22                    16   \n",
       "4                  0.923077                  13                    12   \n",
       "\n",
       "   lexical_avg_word_length  lexical_word_length_variance  \\\n",
       "0                 5.294118                      6.442907   \n",
       "1                 6.000000                      9.000000   \n",
       "2                 4.968750                      4.655273   \n",
       "3                 5.409091                      8.787190   \n",
       "4                 6.153846                      7.207101   \n",
       "\n",
       "   lexical_stopword_ratio  \n",
       "0                0.411765  \n",
       "1                0.277778  \n",
       "2                0.437500  \n",
       "3                0.500000  \n",
       "4                0.384615  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.concat([df_test, df_lexical], axis=1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed92b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "stylistic_features = [\n",
    "    fe.extract_stylistic_features(textos[i], len(processed_texts[i]))\n",
    "    for i in tqdm(range(len(textos)), desc=\"Extraindo features estilísticas\")\n",
    "]\n",
    "df_syntactic = pd.DataFrame(stylistic_features)\n",
    "df_syntactic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cabf0795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>origin</th>\n",
       "      <th>model</th>\n",
       "      <th>lexical_type_token_ratio</th>\n",
       "      <th>lexical_word_count</th>\n",
       "      <th>lexical_unique_words</th>\n",
       "      <th>lexical_avg_word_length</th>\n",
       "      <th>lexical_word_length_variance</th>\n",
       "      <th>lexical_stopword_ratio</th>\n",
       "      <th>stylistic_random_uppercase</th>\n",
       "      <th>stylistic_repeated_chars</th>\n",
       "      <th>stylistic_repeated_words</th>\n",
       "      <th>stylistic_exclamation_density</th>\n",
       "      <th>stylistic_question_density</th>\n",
       "      <th>stylistic_ellipsis_count</th>\n",
       "      <th>stylistic_emoji_density</th>\n",
       "      <th>stylistic_emoticon_density</th>\n",
       "      <th>stylistic_capitalization_inconsistency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our rules are the most robust, the president c...</td>\n",
       "      <td>AI</td>\n",
       "      <td>chat gpt</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>5.294118</td>\n",
       "      <td>6.442907</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>...associating outsiders with danger and extre...</td>\n",
       "      <td>AI</td>\n",
       "      <td>chat gpt</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...alarms were raised in the initial stages of...</td>\n",
       "      <td>AI</td>\n",
       "      <td>chat gpt</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>4.968750</td>\n",
       "      <td>4.655273</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The opposition] utilizes every tool to questi...</td>\n",
       "      <td>AI</td>\n",
       "      <td>chat gpt</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>5.409091</td>\n",
       "      <td>8.787190</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The governor's] fixation with health protocol...</td>\n",
       "      <td>AI</td>\n",
       "      <td>chat gpt</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>6.153846</td>\n",
       "      <td>7.207101</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text origin     model  \\\n",
       "0  Our rules are the most robust, the president c...     AI  chat gpt   \n",
       "1  ...associating outsiders with danger and extre...     AI  chat gpt   \n",
       "2  ...alarms were raised in the initial stages of...     AI  chat gpt   \n",
       "3  [The opposition] utilizes every tool to questi...     AI  chat gpt   \n",
       "4  [The governor's] fixation with health protocol...     AI  chat gpt   \n",
       "\n",
       "   lexical_type_token_ratio  lexical_word_count  lexical_unique_words  \\\n",
       "0                  0.882353                  17                    15   \n",
       "1                  1.000000                  18                    18   \n",
       "2                  0.937500                  32                    30   \n",
       "3                  0.727273                  22                    16   \n",
       "4                  0.923077                  13                    12   \n",
       "\n",
       "   lexical_avg_word_length  lexical_word_length_variance  \\\n",
       "0                 5.294118                      6.442907   \n",
       "1                 6.000000                      9.000000   \n",
       "2                 4.968750                      4.655273   \n",
       "3                 5.409091                      8.787190   \n",
       "4                 6.153846                      7.207101   \n",
       "\n",
       "   lexical_stopword_ratio  stylistic_random_uppercase  \\\n",
       "0                0.411765                           0   \n",
       "1                0.277778                           0   \n",
       "2                0.437500                           0   \n",
       "3                0.500000                           0   \n",
       "4                0.384615                           0   \n",
       "\n",
       "   stylistic_repeated_chars  stylistic_repeated_words  \\\n",
       "0                         0                         0   \n",
       "1                         1                         0   \n",
       "2                         1                         0   \n",
       "3                         0                         0   \n",
       "4                         0                         0   \n",
       "\n",
       "   stylistic_exclamation_density  stylistic_question_density  \\\n",
       "0                            0.0                         0.0   \n",
       "1                            0.0                         0.0   \n",
       "2                            0.0                         0.0   \n",
       "3                            0.0                         0.0   \n",
       "4                            0.0                         0.0   \n",
       "\n",
       "   stylistic_ellipsis_count  stylistic_emoji_density  \\\n",
       "0                         0                      0.0   \n",
       "1                         1                      0.0   \n",
       "2                         1                      0.0   \n",
       "3                         0                      0.0   \n",
       "4                         0                      0.0   \n",
       "\n",
       "   stylistic_emoticon_density  stylistic_capitalization_inconsistency  \n",
       "0                         0.0                                0.000000  \n",
       "1                         0.0                                0.055556  \n",
       "2                         0.0                                0.000000  \n",
       "3                         0.0                                0.000000  \n",
       "4                         0.0                                0.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.concat([df_test, df_syntactic], axis=1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918e9a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2927578/763372016.py:6: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_test = pd.read_csv('df_pronto/df_2pronto.csv')\n",
      "Tokenizando textos: 100%|██████████| 200000/200000 [00:36<00:00, 5427.80it/s]\n",
      "Extraindo features estilísticas: 100%|██████████| 200000/200000 [00:03<00:00, 64147.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stylistic_random_uppercase</th>\n",
       "      <th>stylistic_capitalization_inconsistency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stylistic_random_uppercase  stylistic_capitalization_inconsistency\n",
       "0                           0                                0.000000\n",
       "1                           0                                0.047619\n",
       "2                           0                                0.000000\n",
       "3                           0                                0.000000\n",
       "4                           0                                0.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# especifico para casos com letra maiuscula \n",
    "df_test = pd.read_csv('df_pronto/df_2pronto.csv')\n",
    "textos = df_test[\"text\"].fillna(\"\").tolist()\n",
    "processed_texts = [fe.preprocess_text_A(texto) for texto in tqdm(textos, desc=\"Tokenizando textos\")]\n",
    "stylistic_features = [\n",
    "    fe.extract_stylistic_featuresA(textos[i], len(processed_texts[i]))\n",
    "    for i in tqdm(range(len(textos)), desc=\"Extraindo features estilísticas\")\n",
    "]\n",
    "df_syntactic = pd.DataFrame(stylistic_features)\n",
    "df_syntactic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e384cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat([df_test, df_syntactic], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f6a3cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Extraindo features estruturais: 100%|██████████| 200000/200000 [00:04<00:00, 41548.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>structural_has_url</th>\n",
       "      <th>structural_has_mention</th>\n",
       "      <th>structural_has_hashtag</th>\n",
       "      <th>structural_is_retweet</th>\n",
       "      <th>structural_url_density</th>\n",
       "      <th>structural_mention_density</th>\n",
       "      <th>structural_hashtag_density</th>\n",
       "      <th>structural_extra_spaces</th>\n",
       "      <th>structural_temporal_markers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   structural_has_url  structural_has_mention  structural_has_hashtag  \\\n",
       "0                   0                       0                       0   \n",
       "1                   0                       0                       0   \n",
       "2                   0                       0                       0   \n",
       "3                   0                       0                       0   \n",
       "4                   0                       0                       0   \n",
       "\n",
       "   structural_is_retweet  structural_url_density  structural_mention_density  \\\n",
       "0                      0                     0.0                         0.0   \n",
       "1                      0                     0.0                         0.0   \n",
       "2                      0                     0.0                         0.0   \n",
       "3                      0                     0.0                         0.0   \n",
       "4                      0                     0.0                         0.0   \n",
       "\n",
       "   structural_hashtag_density  structural_extra_spaces  \\\n",
       "0                         0.0                      0.0   \n",
       "1                         0.0                      0.0   \n",
       "2                         0.0                      0.0   \n",
       "3                         0.0                      0.0   \n",
       "4                         0.0                      0.0   \n",
       "\n",
       "   structural_temporal_markers  \n",
       "0                          0.0  \n",
       "1                          0.0  \n",
       "2                          0.0  \n",
       "3                          0.0  \n",
       "4                          0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structural_features = [\n",
    "    fe.extract_structural_features(textos[i], processed_texts[i], len(processed_texts[i]))\n",
    "    for i in tqdm(range(len(textos)), desc=\"Extraindo features estruturais\")\n",
    "]\n",
    "df_structural = pd.DataFrame(structural_features)\n",
    "df_structural.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15375807",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat([df_test, df_structural], axis=1)\n",
    "df_test.to_csv('df_pronto/df_3pronto.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b99571eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_745779/1100540465.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_test = pd.read_csv('/home/tammy.kojima/Authorship-attribution/df_pronto/df_3pronto.csv')\n"
     ]
    }
   ],
   "source": [
    "df_processed_texts = pd.read_csv('/home/tammy.kojima/Authorship-attribution/df_pronto/df_tokens_gpt.csv')\n",
    "df_test = pd.read_csv('/home/tammy.kojima/Authorship-attribution/df_pronto/df_3pronto.csv')\n",
    "processed_texts = df_processed_texts['processed_text'].apply(ast.literal_eval).tolist()\n",
    "textos = df_test[\"text\"].fillna(\"\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04834061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraindo features sintáticas: 100%|█| 200000/200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>syntactic_pos_tag_entropy</th>\n",
       "      <th>syntactic_pos_bigram_entropy</th>\n",
       "      <th>syntactic_avg_sentence_length</th>\n",
       "      <th>syntactic_subordinating_conj</th>\n",
       "      <th>syntactic_comma_ratio</th>\n",
       "      <th>syntactic_punct_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.936199</td>\n",
       "      <td>2.599302</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.875122</td>\n",
       "      <td>2.639341</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.958491</td>\n",
       "      <td>3.031515</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.648841</td>\n",
       "      <td>2.193785</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.631345</td>\n",
       "      <td>2.253858</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   syntactic_pos_tag_entropy  syntactic_pos_bigram_entropy  \\\n",
       "0                   1.936199                      2.599302   \n",
       "1                   1.875122                      2.639341   \n",
       "2                   1.958491                      3.031515   \n",
       "3                   1.648841                      2.193785   \n",
       "4                   1.631345                      2.253858   \n",
       "\n",
       "   syntactic_avg_sentence_length  syntactic_subordinating_conj  \\\n",
       "0                           17.0                           0.0   \n",
       "1                           18.0                           0.0   \n",
       "2                           32.0                           0.0   \n",
       "3                           22.0                           0.0   \n",
       "4                           13.0                           0.0   \n",
       "\n",
       "   syntactic_comma_ratio  syntactic_punct_ratio  \n",
       "0                    0.0                    0.0  \n",
       "1                    0.0                    0.0  \n",
       "2                    0.0                    0.0  \n",
       "3                    0.0                    0.0  \n",
       "4                    0.0                    0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# falta fazer esse \n",
    "syntactic_features = [\n",
    "    fe.extract_syntactic_features(tokens)\n",
    "    for tokens in tqdm(processed_texts, desc=\"Extraindo features sintáticas\")\n",
    "]\n",
    "df_syntactic = pd.DataFrame(syntactic_features)\n",
    "df_syntactic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a860d3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>origin</th>\n",
       "      <th>model</th>\n",
       "      <th>lexical_type_token_ratio</th>\n",
       "      <th>lexical_word_count</th>\n",
       "      <th>lexical_unique_words</th>\n",
       "      <th>lexical_avg_word_length</th>\n",
       "      <th>lexical_word_length_variance</th>\n",
       "      <th>lexical_stopword_ratio</th>\n",
       "      <th>stylistic_random_uppercase</th>\n",
       "      <th>...</th>\n",
       "      <th>structural_mention_density</th>\n",
       "      <th>structural_hashtag_density</th>\n",
       "      <th>structural_extra_spaces</th>\n",
       "      <th>structural_temporal_markers</th>\n",
       "      <th>syntactic_pos_tag_entropy</th>\n",
       "      <th>syntactic_pos_bigram_entropy</th>\n",
       "      <th>syntactic_avg_sentence_length</th>\n",
       "      <th>syntactic_subordinating_conj</th>\n",
       "      <th>syntactic_comma_ratio</th>\n",
       "      <th>syntactic_punct_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our rules are the most robust, the president c...</td>\n",
       "      <td>AI</td>\n",
       "      <td>chat gpt</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>5.294118</td>\n",
       "      <td>6.442907</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.936199</td>\n",
       "      <td>2.599302</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>...associating outsiders with danger and extre...</td>\n",
       "      <td>AI</td>\n",
       "      <td>chat gpt</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.875122</td>\n",
       "      <td>2.639341</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...alarms were raised in the initial stages of...</td>\n",
       "      <td>AI</td>\n",
       "      <td>chat gpt</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>4.968750</td>\n",
       "      <td>4.655273</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.958491</td>\n",
       "      <td>3.031515</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The opposition] utilizes every tool to questi...</td>\n",
       "      <td>AI</td>\n",
       "      <td>chat gpt</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>5.409091</td>\n",
       "      <td>8.787190</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.648841</td>\n",
       "      <td>2.193785</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The governor's] fixation with health protocol...</td>\n",
       "      <td>AI</td>\n",
       "      <td>chat gpt</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>6.153846</td>\n",
       "      <td>7.207101</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.631345</td>\n",
       "      <td>2.253858</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text origin     model  \\\n",
       "0  Our rules are the most robust, the president c...     AI  chat gpt   \n",
       "1  ...associating outsiders with danger and extre...     AI  chat gpt   \n",
       "2  ...alarms were raised in the initial stages of...     AI  chat gpt   \n",
       "3  [The opposition] utilizes every tool to questi...     AI  chat gpt   \n",
       "4  [The governor's] fixation with health protocol...     AI  chat gpt   \n",
       "\n",
       "   lexical_type_token_ratio  lexical_word_count  lexical_unique_words  \\\n",
       "0                  0.882353                  17                    15   \n",
       "1                  1.000000                  18                    18   \n",
       "2                  0.937500                  32                    30   \n",
       "3                  0.727273                  22                    16   \n",
       "4                  0.923077                  13                    12   \n",
       "\n",
       "   lexical_avg_word_length  lexical_word_length_variance  \\\n",
       "0                 5.294118                      6.442907   \n",
       "1                 6.000000                      9.000000   \n",
       "2                 4.968750                      4.655273   \n",
       "3                 5.409091                      8.787190   \n",
       "4                 6.153846                      7.207101   \n",
       "\n",
       "   lexical_stopword_ratio  stylistic_random_uppercase  ...  \\\n",
       "0                0.411765                           0  ...   \n",
       "1                0.277778                           0  ...   \n",
       "2                0.437500                           0  ...   \n",
       "3                0.500000                           0  ...   \n",
       "4                0.384615                           0  ...   \n",
       "\n",
       "   structural_mention_density  structural_hashtag_density  \\\n",
       "0                         0.0                         0.0   \n",
       "1                         0.0                         0.0   \n",
       "2                         0.0                         0.0   \n",
       "3                         0.0                         0.0   \n",
       "4                         0.0                         0.0   \n",
       "\n",
       "   structural_extra_spaces  structural_temporal_markers  \\\n",
       "0                      0.0                          0.0   \n",
       "1                      0.0                          0.0   \n",
       "2                      0.0                          0.0   \n",
       "3                      0.0                          0.0   \n",
       "4                      0.0                          0.0   \n",
       "\n",
       "   syntactic_pos_tag_entropy  syntactic_pos_bigram_entropy  \\\n",
       "0                   1.936199                      2.599302   \n",
       "1                   1.875122                      2.639341   \n",
       "2                   1.958491                      3.031515   \n",
       "3                   1.648841                      2.193785   \n",
       "4                   1.631345                      2.253858   \n",
       "\n",
       "   syntactic_avg_sentence_length  syntactic_subordinating_conj  \\\n",
       "0                           17.0                           0.0   \n",
       "1                           18.0                           0.0   \n",
       "2                           32.0                           0.0   \n",
       "3                           22.0                           0.0   \n",
       "4                           13.0                           0.0   \n",
       "\n",
       "   syntactic_comma_ratio  syntactic_punct_ratio  \n",
       "0                    0.0                    0.0  \n",
       "1                    0.0                    0.0  \n",
       "2                    0.0                    0.0  \n",
       "3                    0.0                    0.0  \n",
       "4                    0.0                    0.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.concat([df_test, df_syntactic], axis=1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d40c6431",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed_texts = pd.read_csv('/home/tammy.kojima/Authorship-attribution/df_pronto/df_tokens_gpt.csv')\n",
    "\n",
    "processed_texts = df_processed_texts['processed_text'].apply(ast.literal_eval).tolist()\n",
    "textos = df[\"text\"].fillna(\"\").tolist()\n",
    "\n",
    "X_new_features = fe.extract_features_batch(textos, processed_texts = processed_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e127a728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ai_perplexity_score</th>\n",
       "      <th>ai_repeated_ngrams</th>\n",
       "      <th>ai_topic_shifts</th>\n",
       "      <th>ai_safety_disclaimers</th>\n",
       "      <th>ai_hedging_language</th>\n",
       "      <th>complexity_subordinating_ratio</th>\n",
       "      <th>complexity_long_sentences</th>\n",
       "      <th>complexity_rare_words</th>\n",
       "      <th>complexity_syntactic_depth</th>\n",
       "      <th>temporal_recent_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>chatgpt_structured_output</th>\n",
       "      <th>chatgpt_overly_polite</th>\n",
       "      <th>chatgpt_disclaimer_density</th>\n",
       "      <th>chatgpt_assistant_patterns</th>\n",
       "      <th>mistral_self_ref</th>\n",
       "      <th>mistral_structured_density</th>\n",
       "      <th>mistral_technical_jargon</th>\n",
       "      <th>mistral_non_english_density</th>\n",
       "      <th>mistral_step_reasoning</th>\n",
       "      <th>mistral_low_ethical_disclaimers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.227273</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ai_perplexity_score  ai_repeated_ngrams  ai_topic_shifts  \\\n",
       "0             0.882353                 0.0         1.714286   \n",
       "1             1.000000                 0.0         1.625000   \n",
       "2             0.937500                 0.0         1.227273   \n",
       "3             0.727273                 0.0         1.250000   \n",
       "4             0.923077                 0.0         2.666667   \n",
       "\n",
       "   ai_safety_disclaimers  ai_hedging_language  complexity_subordinating_ratio  \\\n",
       "0                      0             0.000000                             0.0   \n",
       "1                      0             0.000000                             0.0   \n",
       "2                      0             0.000000                             0.0   \n",
       "3                      0             0.000000                             0.0   \n",
       "4                      0             0.076923                             0.0   \n",
       "\n",
       "   complexity_long_sentences  complexity_rare_words  \\\n",
       "0                        1.0               0.764706   \n",
       "1                        0.0               0.777778   \n",
       "2                        1.0               0.812500   \n",
       "3                        1.0               0.590909   \n",
       "4                        1.0               0.769231   \n",
       "\n",
       "   complexity_syntactic_depth  temporal_recent_ratio  ...  \\\n",
       "0                    1.500000                    0.0  ...   \n",
       "1                    1.750000                    0.0  ...   \n",
       "2                    2.857143                    0.0  ...   \n",
       "3                    2.166667                    0.0  ...   \n",
       "4                    1.333333                    0.0  ...   \n",
       "\n",
       "   chatgpt_structured_output  chatgpt_overly_polite  \\\n",
       "0                        0.0                    0.0   \n",
       "1                        0.0                    0.0   \n",
       "2                        0.0                    0.0   \n",
       "3                        0.0                    0.0   \n",
       "4                        0.0                    0.0   \n",
       "\n",
       "   chatgpt_disclaimer_density  chatgpt_assistant_patterns  mistral_self_ref  \\\n",
       "0                         0.0                         0.0               0.0   \n",
       "1                         0.0                         0.0               0.0   \n",
       "2                         0.0                         0.0               0.0   \n",
       "3                         0.0                         0.0               0.0   \n",
       "4                         0.0                         0.0               0.0   \n",
       "\n",
       "   mistral_structured_density  mistral_technical_jargon  \\\n",
       "0                         0.0                       0.0   \n",
       "1                         0.0                       0.0   \n",
       "2                         0.0                       0.0   \n",
       "3                         0.0                       0.0   \n",
       "4                         0.0                       0.0   \n",
       "\n",
       "   mistral_non_english_density  mistral_step_reasoning  \\\n",
       "0                          0.0                     0.0   \n",
       "1                          0.0                     0.0   \n",
       "2                          0.0                     0.0   \n",
       "3                          0.0                     0.0   \n",
       "4                          0.0                     0.0   \n",
       "\n",
       "   mistral_low_ethical_disclaimers  \n",
       "0                              0.0  \n",
       "1                              0.0  \n",
       "2                              0.0  \n",
       "3                              0.0  \n",
       "4                              0.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features = pd.DataFrame(X_new_features)\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ab9bc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>origin</th>\n",
       "      <th>lexical_type_token_ratio</th>\n",
       "      <th>lexical_word_count</th>\n",
       "      <th>lexical_unique_words</th>\n",
       "      <th>lexical_avg_word_length</th>\n",
       "      <th>lexical_word_length_variance</th>\n",
       "      <th>lexical_stopword_ratio</th>\n",
       "      <th>stylistic_random_uppercase</th>\n",
       "      <th>stylistic_repeated_chars</th>\n",
       "      <th>...</th>\n",
       "      <th>with the</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>you</th>\n",
       "      <th>you are</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our rules are the most robust, the president c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>5.294118</td>\n",
       "      <td>6.442907</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>...associating outsiders with danger and extre...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...alarms were raised in the initial stages of...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>4.968750</td>\n",
       "      <td>4.655273</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The opposition] utilizes every tool to questi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>5.409091</td>\n",
       "      <td>8.787190</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The governor's] fixation with health protocol...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>6.153846</td>\n",
       "      <td>7.207101</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 334 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  origin  \\\n",
       "0  Our rules are the most robust, the president c...       1   \n",
       "1  ...associating outsiders with danger and extre...       1   \n",
       "2  ...alarms were raised in the initial stages of...       1   \n",
       "3  [The opposition] utilizes every tool to questi...       1   \n",
       "4  [The governor's] fixation with health protocol...       1   \n",
       "\n",
       "   lexical_type_token_ratio  lexical_word_count  lexical_unique_words  \\\n",
       "0                  0.882353                  17                    15   \n",
       "1                  1.000000                  18                    18   \n",
       "2                  0.937500                  32                    30   \n",
       "3                  0.727273                  22                    16   \n",
       "4                  0.923077                  13                    12   \n",
       "\n",
       "   lexical_avg_word_length  lexical_word_length_variance  \\\n",
       "0                 5.294118                      6.442907   \n",
       "1                 6.000000                      9.000000   \n",
       "2                 4.968750                      4.655273   \n",
       "3                 5.409091                      8.787190   \n",
       "4                 6.153846                      7.207101   \n",
       "\n",
       "   lexical_stopword_ratio  stylistic_random_uppercase  \\\n",
       "0                0.411765                           0   \n",
       "1                0.277778                           0   \n",
       "2                0.437500                           0   \n",
       "3                0.500000                           0   \n",
       "4                0.384615                           0   \n",
       "\n",
       "   stylistic_repeated_chars  ...  with the  work  working  world  would  year  \\\n",
       "0                         0  ...         0     0        0      0      0     0   \n",
       "1                         1  ...         0     0        0      0      0     0   \n",
       "2                         1  ...         0     0        0      0      0     0   \n",
       "3                         0  ...         0     0        0      0      0     0   \n",
       "4                         0  ...         0     0        0      0      0     0   \n",
       "\n",
       "   years  you  you are  your  \n",
       "0      0    0        0     0  \n",
       "1      0    0        0     0  \n",
       "2      0    0        0     0  \n",
       "3      0    0        0     0  \n",
       "4      0    0        0     0  \n",
       "\n",
       "[5 rows x 334 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30167ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>origin</th>\n",
       "      <th>lexical_type_token_ratio</th>\n",
       "      <th>lexical_word_count</th>\n",
       "      <th>lexical_unique_words</th>\n",
       "      <th>lexical_avg_word_length</th>\n",
       "      <th>lexical_word_length_variance</th>\n",
       "      <th>lexical_stopword_ratio</th>\n",
       "      <th>stylistic_random_uppercase</th>\n",
       "      <th>stylistic_repeated_chars</th>\n",
       "      <th>...</th>\n",
       "      <th>chatgpt_structured_output</th>\n",
       "      <th>chatgpt_overly_polite</th>\n",
       "      <th>chatgpt_disclaimer_density</th>\n",
       "      <th>chatgpt_assistant_patterns</th>\n",
       "      <th>mistral_self_ref</th>\n",
       "      <th>mistral_structured_density</th>\n",
       "      <th>mistral_technical_jargon</th>\n",
       "      <th>mistral_non_english_density</th>\n",
       "      <th>mistral_step_reasoning</th>\n",
       "      <th>mistral_low_ethical_disclaimers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our rules are the most robust, the president c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>5.294118</td>\n",
       "      <td>6.442907</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>...associating outsiders with danger and extre...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...alarms were raised in the initial stages of...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>4.968750</td>\n",
       "      <td>4.655273</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The opposition] utilizes every tool to questi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>5.409091</td>\n",
       "      <td>8.787190</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The governor's] fixation with health protocol...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>6.153846</td>\n",
       "      <td>7.207101</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 361 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  origin  \\\n",
       "0  Our rules are the most robust, the president c...       1   \n",
       "1  ...associating outsiders with danger and extre...       1   \n",
       "2  ...alarms were raised in the initial stages of...       1   \n",
       "3  [The opposition] utilizes every tool to questi...       1   \n",
       "4  [The governor's] fixation with health protocol...       1   \n",
       "\n",
       "   lexical_type_token_ratio  lexical_word_count  lexical_unique_words  \\\n",
       "0                  0.882353                  17                    15   \n",
       "1                  1.000000                  18                    18   \n",
       "2                  0.937500                  32                    30   \n",
       "3                  0.727273                  22                    16   \n",
       "4                  0.923077                  13                    12   \n",
       "\n",
       "   lexical_avg_word_length  lexical_word_length_variance  \\\n",
       "0                 5.294118                      6.442907   \n",
       "1                 6.000000                      9.000000   \n",
       "2                 4.968750                      4.655273   \n",
       "3                 5.409091                      8.787190   \n",
       "4                 6.153846                      7.207101   \n",
       "\n",
       "   lexical_stopword_ratio  stylistic_random_uppercase  \\\n",
       "0                0.411765                           0   \n",
       "1                0.277778                           0   \n",
       "2                0.437500                           0   \n",
       "3                0.500000                           0   \n",
       "4                0.384615                           0   \n",
       "\n",
       "   stylistic_repeated_chars  ...  chatgpt_structured_output  \\\n",
       "0                         0  ...                        0.0   \n",
       "1                         1  ...                        0.0   \n",
       "2                         1  ...                        0.0   \n",
       "3                         0  ...                        0.0   \n",
       "4                         0  ...                        0.0   \n",
       "\n",
       "   chatgpt_overly_polite  chatgpt_disclaimer_density  \\\n",
       "0                    0.0                         0.0   \n",
       "1                    0.0                         0.0   \n",
       "2                    0.0                         0.0   \n",
       "3                    0.0                         0.0   \n",
       "4                    0.0                         0.0   \n",
       "\n",
       "   chatgpt_assistant_patterns  mistral_self_ref  mistral_structured_density  \\\n",
       "0                         0.0               0.0                         0.0   \n",
       "1                         0.0               0.0                         0.0   \n",
       "2                         0.0               0.0                         0.0   \n",
       "3                         0.0               0.0                         0.0   \n",
       "4                         0.0               0.0                         0.0   \n",
       "\n",
       "   mistral_technical_jargon  mistral_non_english_density  \\\n",
       "0                       0.0                          0.0   \n",
       "1                       0.0                          0.0   \n",
       "2                       0.0                          0.0   \n",
       "3                       0.0                          0.0   \n",
       "4                       0.0                          0.0   \n",
       "\n",
       "   mistral_step_reasoning  mistral_low_ethical_disclaimers  \n",
       "0                     0.0                              0.0  \n",
       "1                     0.0                              0.0  \n",
       "2                     0.0                              0.0  \n",
       "3                     0.0                              0.0  \n",
       "4                     0.0                              0.0  \n",
       "\n",
       "[5 rows x 361 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.concat([df, df_features], axis=1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96e7102d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>19</th>\n",
       "      <th>about</th>\n",
       "      <th>about the</th>\n",
       "      <th>action</th>\n",
       "      <th>administration</th>\n",
       "      <th>administration is</th>\n",
       "      <th>after</th>\n",
       "      <th>again</th>\n",
       "      <th>against</th>\n",
       "      <th>all</th>\n",
       "      <th>...</th>\n",
       "      <th>with the</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>you</th>\n",
       "      <th>you are</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   19  about  about the  action  administration  administration is  after  \\\n",
       "0   0      0          0       0               0                  0      0   \n",
       "1   0      0          0       0               0                  0      0   \n",
       "2   0      0          0       0               0                  0      0   \n",
       "3   0      0          0       0               0                  0      0   \n",
       "4   0      0          0       0               0                  0      0   \n",
       "\n",
       "   again  against  all  ...  with the  work  working  world  would  year  \\\n",
       "0      0        0    0  ...         0     0        0      0      0     0   \n",
       "1      0        0    0  ...         0     0        0      0      0     0   \n",
       "2      0        0    0  ...         0     0        0      0      0     0   \n",
       "3      0        0    0  ...         0     0        0      0      0     0   \n",
       "4      0        0    0  ...         0     0        0      0      0     0   \n",
       "\n",
       "   years  you  you are  your  \n",
       "0      0    0        0     0  \n",
       "1      0    0        0     0  \n",
       "2      0    0        0     0  \n",
       "3      0    0        0     0  \n",
       "4      0    0        0     0  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo de uso básico\n",
    "ngrams_df = fe.extract_ngrams_features(processed_texts, max_features=300)\n",
    "ngrams_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193a3553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetar os índices de ambos os DataFrames\n",
    "df_test_reset = df.reset_index(drop=True)\n",
    "ngrams_df_reset = ngrams_df.reset_index(drop=True)\n",
    "\n",
    "# Agora concatenar\n",
    "df_combined = pd.concat([df_test_reset, ngrams_df_reset], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67511cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_reset = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b9a1848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>origin</th>\n",
       "      <th>lexical_type_token_ratio</th>\n",
       "      <th>lexical_word_count</th>\n",
       "      <th>lexical_unique_words</th>\n",
       "      <th>lexical_avg_word_length</th>\n",
       "      <th>lexical_word_length_variance</th>\n",
       "      <th>lexical_stopword_ratio</th>\n",
       "      <th>stylistic_random_uppercase</th>\n",
       "      <th>stylistic_repeated_chars</th>\n",
       "      <th>...</th>\n",
       "      <th>with the</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>you</th>\n",
       "      <th>you are</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our rules are the most robust, the president c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>5.294118</td>\n",
       "      <td>6.442907</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>...associating outsiders with danger and extre...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...alarms were raised in the initial stages of...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>4.968750</td>\n",
       "      <td>4.655273</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The opposition] utilizes every tool to questi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>5.409091</td>\n",
       "      <td>8.787190</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The governor's] fixation with health protocol...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>6.153846</td>\n",
       "      <td>7.207101</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 334 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  origin  \\\n",
       "0  Our rules are the most robust, the president c...       1   \n",
       "1  ...associating outsiders with danger and extre...       1   \n",
       "2  ...alarms were raised in the initial stages of...       1   \n",
       "3  [The opposition] utilizes every tool to questi...       1   \n",
       "4  [The governor's] fixation with health protocol...       1   \n",
       "\n",
       "   lexical_type_token_ratio  lexical_word_count  lexical_unique_words  \\\n",
       "0                  0.882353                  17                    15   \n",
       "1                  1.000000                  18                    18   \n",
       "2                  0.937500                  32                    30   \n",
       "3                  0.727273                  22                    16   \n",
       "4                  0.923077                  13                    12   \n",
       "\n",
       "   lexical_avg_word_length  lexical_word_length_variance  \\\n",
       "0                 5.294118                      6.442907   \n",
       "1                 6.000000                      9.000000   \n",
       "2                 4.968750                      4.655273   \n",
       "3                 5.409091                      8.787190   \n",
       "4                 6.153846                      7.207101   \n",
       "\n",
       "   lexical_stopword_ratio  stylistic_random_uppercase  \\\n",
       "0                0.411765                           0   \n",
       "1                0.277778                           0   \n",
       "2                0.437500                           0   \n",
       "3                0.500000                           0   \n",
       "4                0.384615                           0   \n",
       "\n",
       "   stylistic_repeated_chars  ...  with the  work  working  world  would  year  \\\n",
       "0                         0  ...         0     0        0      0      0     0   \n",
       "1                         1  ...         0     0        0      0      0     0   \n",
       "2                         1  ...         0     0        0      0      0     0   \n",
       "3                         0  ...         0     0        0      0      0     0   \n",
       "4                         0  ...         0     0        0      0      0     0   \n",
       "\n",
       "   years  you  you are  your  \n",
       "0      0    0        0     0  \n",
       "1      0    0        0     0  \n",
       "2      0    0        0     0  \n",
       "3      0    0        0     0  \n",
       "4      0    0        0     0  \n",
       "\n",
       "[5 rows x 334 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Troca IA → 1 e human → 0\n",
    "df_test_reset['origin'] = df_test_reset['origin'].replace({'AI': 1, 'human': 0})\n",
    "\n",
    "df_test_reset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10e5e09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_745779/91803334.py:1: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  df_combined = df_combined.apply(lambda x: x.sparse.to_dense() if pd.api.types.is_sparse(x) else x)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>lexical_type_token_ratio</th>\n",
       "      <th>lexical_word_count</th>\n",
       "      <th>lexical_unique_words</th>\n",
       "      <th>lexical_avg_word_length</th>\n",
       "      <th>lexical_word_length_variance</th>\n",
       "      <th>lexical_stopword_ratio</th>\n",
       "      <th>stylistic_random_uppercase</th>\n",
       "      <th>stylistic_repeated_chars</th>\n",
       "      <th>stylistic_repeated_words</th>\n",
       "      <th>...</th>\n",
       "      <th>with the</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>you</th>\n",
       "      <th>you are</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.939904</td>\n",
       "      <td>20.395885</td>\n",
       "      <td>18.869735</td>\n",
       "      <td>5.145131</td>\n",
       "      <td>10.948684</td>\n",
       "      <td>0.421463</td>\n",
       "      <td>0.324975</td>\n",
       "      <td>0.130065</td>\n",
       "      <td>0.014420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013875</td>\n",
       "      <td>0.027415</td>\n",
       "      <td>0.012815</td>\n",
       "      <td>0.042780</td>\n",
       "      <td>0.023140</td>\n",
       "      <td>0.017950</td>\n",
       "      <td>0.023415</td>\n",
       "      <td>0.168210</td>\n",
       "      <td>0.014765</td>\n",
       "      <td>0.049805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500001</td>\n",
       "      <td>0.065652</td>\n",
       "      <td>9.664566</td>\n",
       "      <td>8.529665</td>\n",
       "      <td>1.318695</td>\n",
       "      <td>13.854440</td>\n",
       "      <td>0.159344</td>\n",
       "      <td>0.468367</td>\n",
       "      <td>0.336376</td>\n",
       "      <td>0.119215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117824</td>\n",
       "      <td>0.170422</td>\n",
       "      <td>0.113406</td>\n",
       "      <td>0.209237</td>\n",
       "      <td>0.159545</td>\n",
       "      <td>0.138665</td>\n",
       "      <td>0.161018</td>\n",
       "      <td>0.503057</td>\n",
       "      <td>0.142888</td>\n",
       "      <td>0.244448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.375000</td>\n",
       "      <td>4.093333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>4.944444</td>\n",
       "      <td>6.616071</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>5.608696</td>\n",
       "      <td>12.290000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>2348.913580</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              origin  lexical_type_token_ratio  lexical_word_count  \\\n",
       "count  200000.000000             200000.000000       200000.000000   \n",
       "mean        0.500000                  0.939904           20.395885   \n",
       "std         0.500001                  0.065652            9.664566   \n",
       "min         0.000000                  0.076923            1.000000   \n",
       "25%         0.000000                  0.903226           12.000000   \n",
       "50%         0.500000                  0.950000           20.000000   \n",
       "75%         1.000000                  1.000000           28.000000   \n",
       "max         1.000000                  1.000000          107.000000   \n",
       "\n",
       "       lexical_unique_words  lexical_avg_word_length  \\\n",
       "count         200000.000000            200000.000000   \n",
       "mean              18.869735                 5.145131   \n",
       "std                8.529665                 1.318695   \n",
       "min                1.000000                 1.000000   \n",
       "25%               12.000000                 4.375000   \n",
       "50%               19.000000                 4.944444   \n",
       "75%               26.000000                 5.608696   \n",
       "max               76.000000                76.000000   \n",
       "\n",
       "       lexical_word_length_variance  lexical_stopword_ratio  \\\n",
       "count                 200000.000000           200000.000000   \n",
       "mean                      10.948684                0.421463   \n",
       "std                       13.854440                0.159344   \n",
       "min                        0.000000                0.000000   \n",
       "25%                        4.093333                0.333333   \n",
       "50%                        6.616071                0.437500   \n",
       "75%                       12.290000                0.533333   \n",
       "max                     2348.913580                1.000000   \n",
       "\n",
       "       stylistic_random_uppercase  stylistic_repeated_chars  \\\n",
       "count               200000.000000             200000.000000   \n",
       "mean                     0.324975                  0.130065   \n",
       "std                      0.468367                  0.336376   \n",
       "min                      0.000000                  0.000000   \n",
       "25%                      0.000000                  0.000000   \n",
       "50%                      0.000000                  0.000000   \n",
       "75%                      1.000000                  0.000000   \n",
       "max                      1.000000                  1.000000   \n",
       "\n",
       "       stylistic_repeated_words  ...       with the           work  \\\n",
       "count             200000.000000  ...  200000.000000  200000.000000   \n",
       "mean                   0.014420  ...       0.013875       0.027415   \n",
       "std                    0.119215  ...       0.117824       0.170422   \n",
       "min                    0.000000  ...       0.000000       0.000000   \n",
       "25%                    0.000000  ...       0.000000       0.000000   \n",
       "50%                    0.000000  ...       0.000000       0.000000   \n",
       "75%                    0.000000  ...       0.000000       0.000000   \n",
       "max                    1.000000  ...       3.000000       4.000000   \n",
       "\n",
       "             working          world          would           year  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.012815       0.042780       0.023140       0.017950   \n",
       "std         0.113406       0.209237       0.159545       0.138665   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         2.000000       4.000000       5.000000       4.000000   \n",
       "\n",
       "               years            you        you are           your  \n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000  \n",
       "mean        0.023415       0.168210       0.014765       0.049805  \n",
       "std         0.161018       0.503057       0.142888       0.244448  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000       0.000000  \n",
       "50%         0.000000       0.000000       0.000000       0.000000  \n",
       "75%         0.000000       0.000000       0.000000       0.000000  \n",
       "max         4.000000      13.000000       6.000000       5.000000  \n",
       "\n",
       "[8 rows x 333 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined = df_combined.apply(lambda x: x.sparse.to_dense() if pd.api.types.is_sparse(x) else x)\n",
    "df_combined.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bf5279e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_combined' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_combined\u001b[49m\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_combined' is not defined"
     ]
    }
   ],
   "source": [
    "df_combined.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7938998a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_test_reset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/tammy.kojima/Authorship-attribution/df_pronto/df_gpt_com_features.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/meu_ambiente/lib/python3.9/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/meu_ambiente/lib/python3.9/site-packages/pandas/core/generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3965\u001b[0m )\n\u001b[0;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/meu_ambiente/lib/python3.9/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/miniconda3/envs/meu_ambiente/lib/python3.9/site-packages/pandas/io/formats/csvs.py:270\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/meu_ambiente/lib/python3.9/site-packages/pandas/io/formats/csvs.py:275\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/meu_ambiente/lib/python3.9/site-packages/pandas/io/formats/csvs.py:313\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/meu_ambiente/lib/python3.9/site-packages/pandas/io/formats/csvs.py:324\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    321\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(res\u001b[38;5;241m.\u001b[39m_iter_column_arrays())\n\u001b[1;32m    323\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_get_values_for_csv(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n\u001b[0;32m--> 324\u001b[0m \u001b[43mlibwriters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_csv_rows\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mwriters.pyx:73\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_test_reset.to_csv(\"/home/tammy.kojima/Authorship-attribution/df_pronto/df_gpt_com_features.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meu_ambiente",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
