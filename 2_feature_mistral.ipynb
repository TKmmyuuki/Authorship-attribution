{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69f8c9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tammy.kojima/miniconda3/envs/meu_ambiente/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-09-07 12:20:20,627\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-09-07 12:20:20,738\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append('/home/tammy.kojima/Authorship-attribution/')\n",
    "import feature_extraction as fe\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ea61e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>length</th>\n",
       "      <th>batch_timestamp</th>\n",
       "      <th>characters_remaining</th>\n",
       "      <th>origin</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>\"The future is here: AI-powered virtual tutors...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>193.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>\"From predictive analytics that identify strug...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>\"Empower your classroom with AI-driven solutio...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>166.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>114.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>\"Let's debunk the myth - AI isn't replacing hu...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>237.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Ever wondered how AI can make teachers' lives ...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>188.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>i've gone to 3rd place! http://bit.ly/VwV6H  p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>human</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>@freshome I read a book that tells exacly that...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>human</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>@ConnecticutSun its ok pic is kind of fuzzy bu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>human</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Feel Like working over the weekend.. I hope i ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>human</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>hopes visitting hours arent over- my dad's in ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>human</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tweet_id                                               text  \\\n",
       "0          1.0  \"The future is here: AI-powered virtual tutors...   \n",
       "1          2.0  \"From predictive analytics that identify strug...   \n",
       "2          3.0  \"Empower your classroom with AI-driven solutio...   \n",
       "3          4.0  \"Let's debunk the myth - AI isn't replacing hu...   \n",
       "4          5.0  Ever wondered how AI can make teachers' lives ...   \n",
       "...        ...                                                ...   \n",
       "9995       NaN  i've gone to 3rd place! http://bit.ly/VwV6H  p...   \n",
       "9996       NaN  @freshome I read a book that tells exacly that...   \n",
       "9997       NaN  @ConnecticutSun its ok pic is kind of fuzzy bu...   \n",
       "9998       NaN  Feel Like working over the weekend.. I hope i ...   \n",
       "9999       NaN  hopes visitting hours arent over- my dad's in ...   \n",
       "\n",
       "                                     topic  length      batch_timestamp  \\\n",
       "0     artificial intelligence in education   193.0  2025-09-07 11:05:21   \n",
       "1     artificial intelligence in education   192.0  2025-09-07 11:05:21   \n",
       "2     artificial intelligence in education   166.0  2025-09-07 11:05:21   \n",
       "3     artificial intelligence in education   237.0  2025-09-07 11:05:21   \n",
       "4     artificial intelligence in education   188.0  2025-09-07 11:05:21   \n",
       "...                                    ...     ...                  ...   \n",
       "9995                                   NaN     NaN                  NaN   \n",
       "9996                                   NaN     NaN                  NaN   \n",
       "9997                                   NaN     NaN                  NaN   \n",
       "9998                                   NaN     NaN                  NaN   \n",
       "9999                                   NaN     NaN                  NaN   \n",
       "\n",
       "      characters_remaining origin  model  \n",
       "0                     87.0    NaN    NaN  \n",
       "1                     88.0    NaN    NaN  \n",
       "2                    114.0    NaN    NaN  \n",
       "3                     43.0    NaN    NaN  \n",
       "4                     92.0    NaN    NaN  \n",
       "...                    ...    ...    ...  \n",
       "9995                   NaN  human    NaN  \n",
       "9996                   NaN  human    NaN  \n",
       "9997                   NaN  human    NaN  \n",
       "9998                   NaN  human    NaN  \n",
       "9999                   NaN  human    NaN  \n",
       "\n",
       "[10000 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mistral = pd.read_csv('/home/tammy.kojima/Authorship-attribution/df_pronto/df_mistral.csv')\n",
    "df_human = pd.read_csv('/home/tammy.kojima/Authorship-attribution/df_pronto/df_human.csv')\n",
    "df_mistral = df_mistral.iloc[:5000]\n",
    "df_human = df_human.iloc[:5000]\n",
    "df_test = pd.concat([df_mistral, df_human], ignore_index=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78c544fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizando textos:   0%|                                                                                                                        | 0/10000 [00:00<?, ?it/s][nltk_data] Error loading punkt: <urlopen error [Errno -2] Name or\n",
      "[nltk_data]     service not known>\n",
      "Tokenizando textos: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:00<00:00, 14653.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokeniza todos os textos primeiro\n",
    "textos = df_test[\"text\"].fillna(\"\").tolist()\n",
    "processed_texts = [fe.preprocess_text(texto) for texto in tqdm(textos, desc=\"Tokenizando textos\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2527736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prossessed_texts = pd.DataFrame({'text': processed_texts})\n",
    "df_prossessed_texts.to_csv('/home/tammy.kojima/Authorship-attribution/df_pronto/df_tokens_mistral.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72cb46ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:00<00:00, 15850.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>length</th>\n",
       "      <th>batch_timestamp</th>\n",
       "      <th>characters_remaining</th>\n",
       "      <th>origin</th>\n",
       "      <th>model</th>\n",
       "      <th>lexical_type_token_ratio</th>\n",
       "      <th>lexical_word_count</th>\n",
       "      <th>lexical_unique_words</th>\n",
       "      <th>lexical_avg_word_length</th>\n",
       "      <th>lexical_word_length_variance</th>\n",
       "      <th>lexical_stopword_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>\"The future is here: AI-powered virtual tutors...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>193.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>18.288889</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>\"From predictive analytics that identify strug...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>5.387097</td>\n",
       "      <td>16.237253</td>\n",
       "      <td>0.129032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>\"Empower your classroom with AI-driven solutio...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>166.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>114.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>5.137931</td>\n",
       "      <td>14.325803</td>\n",
       "      <td>0.068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>\"Let's debunk the myth - AI isn't replacing hu...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>237.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>45</td>\n",
       "      <td>42</td>\n",
       "      <td>4.511111</td>\n",
       "      <td>11.227654</td>\n",
       "      <td>0.088889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Ever wondered how AI can make teachers' lives ...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>188.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>4.735294</td>\n",
       "      <td>10.429931</td>\n",
       "      <td>0.088235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                               text  \\\n",
       "0       1.0  \"The future is here: AI-powered virtual tutors...   \n",
       "1       2.0  \"From predictive analytics that identify strug...   \n",
       "2       3.0  \"Empower your classroom with AI-driven solutio...   \n",
       "3       4.0  \"Let's debunk the myth - AI isn't replacing hu...   \n",
       "4       5.0  Ever wondered how AI can make teachers' lives ...   \n",
       "\n",
       "                                  topic  length      batch_timestamp  \\\n",
       "0  artificial intelligence in education   193.0  2025-09-07 11:05:21   \n",
       "1  artificial intelligence in education   192.0  2025-09-07 11:05:21   \n",
       "2  artificial intelligence in education   166.0  2025-09-07 11:05:21   \n",
       "3  artificial intelligence in education   237.0  2025-09-07 11:05:21   \n",
       "4  artificial intelligence in education   188.0  2025-09-07 11:05:21   \n",
       "\n",
       "   characters_remaining origin  model  lexical_type_token_ratio  \\\n",
       "0                  87.0    NaN    NaN                  0.933333   \n",
       "1                  88.0    NaN    NaN                  0.935484   \n",
       "2                 114.0    NaN    NaN                  0.896552   \n",
       "3                  43.0    NaN    NaN                  0.933333   \n",
       "4                  92.0    NaN    NaN                  1.000000   \n",
       "\n",
       "   lexical_word_count  lexical_unique_words  lexical_avg_word_length  \\\n",
       "0                  30                    28                 5.666667   \n",
       "1                  31                    29                 5.387097   \n",
       "2                  29                    26                 5.137931   \n",
       "3                  45                    42                 4.511111   \n",
       "4                  34                    34                 4.735294   \n",
       "\n",
       "   lexical_word_length_variance  lexical_stopword_ratio  \n",
       "0                     18.288889                0.100000  \n",
       "1                     16.237253                0.129032  \n",
       "2                     14.325803                0.068966  \n",
       "3                     11.227654                0.088889  \n",
       "4                     10.429931                0.088235  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lista para armazenar resultados\n",
    "lexical_features = []\n",
    "\n",
    "for texto in tqdm(textos):\n",
    "    # Tokeniza o texto usando Twokenizer\n",
    "    words = fe.preprocess_text(texto)  # jÃ¡ retorna tokens em lowercase\n",
    "    \n",
    "    # Extrai features lÃ©xicas\n",
    "    features = fe.extract_lexical_features(texto, words)\n",
    "    lexical_features.append(features)\n",
    "\n",
    "df_lexical = pd.DataFrame(lexical_features)\n",
    "df_test = pd.concat([df_test, df_lexical], axis=1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ac11563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraindo features estilÃ­sticas: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:00<00:00, 109506.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>length</th>\n",
       "      <th>batch_timestamp</th>\n",
       "      <th>characters_remaining</th>\n",
       "      <th>origin</th>\n",
       "      <th>model</th>\n",
       "      <th>lexical_type_token_ratio</th>\n",
       "      <th>lexical_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>lexical_avg_word_length</th>\n",
       "      <th>lexical_word_length_variance</th>\n",
       "      <th>lexical_stopword_ratio</th>\n",
       "      <th>stylistic_repeated_chars</th>\n",
       "      <th>stylistic_repeated_words</th>\n",
       "      <th>stylistic_exclamation_density</th>\n",
       "      <th>stylistic_question_density</th>\n",
       "      <th>stylistic_ellipsis_count</th>\n",
       "      <th>stylistic_emoji_density</th>\n",
       "      <th>stylistic_emoticon_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>\"The future is here: AI-powered virtual tutors...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>193.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>18.288889</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>\"From predictive analytics that identify strug...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>5.387097</td>\n",
       "      <td>16.237253</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>\"Empower your classroom with AI-driven solutio...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>166.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>114.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>5.137931</td>\n",
       "      <td>14.325803</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>\"Let's debunk the myth - AI isn't replacing hu...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>237.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>4.511111</td>\n",
       "      <td>11.227654</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Ever wondered how AI can make teachers' lives ...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>188.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>4.735294</td>\n",
       "      <td>10.429931</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                               text  \\\n",
       "0       1.0  \"The future is here: AI-powered virtual tutors...   \n",
       "1       2.0  \"From predictive analytics that identify strug...   \n",
       "2       3.0  \"Empower your classroom with AI-driven solutio...   \n",
       "3       4.0  \"Let's debunk the myth - AI isn't replacing hu...   \n",
       "4       5.0  Ever wondered how AI can make teachers' lives ...   \n",
       "\n",
       "                                  topic  length      batch_timestamp  \\\n",
       "0  artificial intelligence in education   193.0  2025-09-07 11:05:21   \n",
       "1  artificial intelligence in education   192.0  2025-09-07 11:05:21   \n",
       "2  artificial intelligence in education   166.0  2025-09-07 11:05:21   \n",
       "3  artificial intelligence in education   237.0  2025-09-07 11:05:21   \n",
       "4  artificial intelligence in education   188.0  2025-09-07 11:05:21   \n",
       "\n",
       "   characters_remaining origin  model  lexical_type_token_ratio  \\\n",
       "0                  87.0    NaN    NaN                  0.933333   \n",
       "1                  88.0    NaN    NaN                  0.935484   \n",
       "2                 114.0    NaN    NaN                  0.896552   \n",
       "3                  43.0    NaN    NaN                  0.933333   \n",
       "4                  92.0    NaN    NaN                  1.000000   \n",
       "\n",
       "   lexical_word_count  ...  lexical_avg_word_length  \\\n",
       "0                  30  ...                 5.666667   \n",
       "1                  31  ...                 5.387097   \n",
       "2                  29  ...                 5.137931   \n",
       "3                  45  ...                 4.511111   \n",
       "4                  34  ...                 4.735294   \n",
       "\n",
       "   lexical_word_length_variance  lexical_stopword_ratio  \\\n",
       "0                     18.288889                0.100000   \n",
       "1                     16.237253                0.129032   \n",
       "2                     14.325803                0.068966   \n",
       "3                     11.227654                0.088889   \n",
       "4                     10.429931                0.088235   \n",
       "\n",
       "   stylistic_repeated_chars  stylistic_repeated_words  \\\n",
       "0                         0                         0   \n",
       "1                         0                         0   \n",
       "2                         1                         0   \n",
       "3                         0                         0   \n",
       "4                         0                         0   \n",
       "\n",
       "   stylistic_exclamation_density  stylistic_question_density  \\\n",
       "0                       0.066667                    0.000000   \n",
       "1                       0.032258                    0.000000   \n",
       "2                       0.068966                    0.000000   \n",
       "3                       0.022222                    0.000000   \n",
       "4                       0.029412                    0.029412   \n",
       "\n",
       "   stylistic_ellipsis_count  stylistic_emoji_density  \\\n",
       "0                         0                 0.000000   \n",
       "1                         0                 0.032258   \n",
       "2                         1                 0.068966   \n",
       "3                         0                 0.044444   \n",
       "4                         0                 0.029412   \n",
       "\n",
       "   stylistic_emoticon_density  \n",
       "0                         0.0  \n",
       "1                         0.0  \n",
       "2                         0.0  \n",
       "3                         0.0  \n",
       "4                         0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stylistic_features = [\n",
    "    fe.extract_stylistic_features(textos[i], len(processed_texts[i]))\n",
    "    for i in tqdm(range(len(textos)), desc=\"Extraindo features estilÃ­sticas\")\n",
    "]\n",
    "df_stylistic = pd.DataFrame(stylistic_features)\n",
    "df_test = pd.concat([df_test, df_stylistic], axis=1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73f88ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraindo features estruturais: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:00<00:00, 136580.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>length</th>\n",
       "      <th>batch_timestamp</th>\n",
       "      <th>characters_remaining</th>\n",
       "      <th>origin</th>\n",
       "      <th>model</th>\n",
       "      <th>lexical_type_token_ratio</th>\n",
       "      <th>lexical_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>stylistic_emoticon_density</th>\n",
       "      <th>structural_has_url</th>\n",
       "      <th>structural_has_mention</th>\n",
       "      <th>structural_has_hashtag</th>\n",
       "      <th>structural_is_retweet</th>\n",
       "      <th>structural_url_density</th>\n",
       "      <th>structural_mention_density</th>\n",
       "      <th>structural_hashtag_density</th>\n",
       "      <th>structural_extra_spaces</th>\n",
       "      <th>structural_temporal_markers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>\"The future is here: AI-powered virtual tutors...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>193.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>\"From predictive analytics that identify strug...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>\"Empower your classroom with AI-driven solutio...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>166.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>114.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>\"Let's debunk the myth - AI isn't replacing hu...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>237.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Ever wondered how AI can make teachers' lives ...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>188.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                               text  \\\n",
       "0       1.0  \"The future is here: AI-powered virtual tutors...   \n",
       "1       2.0  \"From predictive analytics that identify strug...   \n",
       "2       3.0  \"Empower your classroom with AI-driven solutio...   \n",
       "3       4.0  \"Let's debunk the myth - AI isn't replacing hu...   \n",
       "4       5.0  Ever wondered how AI can make teachers' lives ...   \n",
       "\n",
       "                                  topic  length      batch_timestamp  \\\n",
       "0  artificial intelligence in education   193.0  2025-09-07 11:05:21   \n",
       "1  artificial intelligence in education   192.0  2025-09-07 11:05:21   \n",
       "2  artificial intelligence in education   166.0  2025-09-07 11:05:21   \n",
       "3  artificial intelligence in education   237.0  2025-09-07 11:05:21   \n",
       "4  artificial intelligence in education   188.0  2025-09-07 11:05:21   \n",
       "\n",
       "   characters_remaining origin  model  lexical_type_token_ratio  \\\n",
       "0                  87.0    NaN    NaN                  0.933333   \n",
       "1                  88.0    NaN    NaN                  0.935484   \n",
       "2                 114.0    NaN    NaN                  0.896552   \n",
       "3                  43.0    NaN    NaN                  0.933333   \n",
       "4                  92.0    NaN    NaN                  1.000000   \n",
       "\n",
       "   lexical_word_count  ...  stylistic_emoticon_density  structural_has_url  \\\n",
       "0                  30  ...                         0.0                   0   \n",
       "1                  31  ...                         0.0                   0   \n",
       "2                  29  ...                         0.0                   0   \n",
       "3                  45  ...                         0.0                   0   \n",
       "4                  34  ...                         0.0                   0   \n",
       "\n",
       "   structural_has_mention  structural_has_hashtag  structural_is_retweet  \\\n",
       "0                       0                       1                      0   \n",
       "1                       0                       1                      0   \n",
       "2                       0                       0                      0   \n",
       "3                       0                       1                      0   \n",
       "4                       0                       1                      0   \n",
       "\n",
       "   structural_url_density  structural_mention_density  \\\n",
       "0                     0.0                         0.0   \n",
       "1                     0.0                         0.0   \n",
       "2                     0.0                         0.0   \n",
       "3                     0.0                         0.0   \n",
       "4                     0.0                         0.0   \n",
       "\n",
       "   structural_hashtag_density  structural_extra_spaces  \\\n",
       "0                    0.033333                      0.0   \n",
       "1                    0.032258                      0.0   \n",
       "2                    0.000000                      0.0   \n",
       "3                    0.022222                      0.0   \n",
       "4                    0.029412                      0.0   \n",
       "\n",
       "   structural_temporal_markers  \n",
       "0                          0.0  \n",
       "1                          0.0  \n",
       "2                          0.0  \n",
       "3                          0.0  \n",
       "4                          0.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structural_features = [\n",
    "    fe.extract_structural_features(textos[i], processed_texts[i], len(processed_texts[i]))\n",
    "    for i in tqdm(range(len(textos)), desc=\"Extraindo features estruturais\")\n",
    "]\n",
    "df_structural = pd.DataFrame(structural_features)\n",
    "df_test = pd.concat([df_test, df_structural], axis=1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94c9d66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraindo features sintÃ¡ticas: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:47<00:00, 209.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>length</th>\n",
       "      <th>batch_timestamp</th>\n",
       "      <th>characters_remaining</th>\n",
       "      <th>origin</th>\n",
       "      <th>model</th>\n",
       "      <th>lexical_type_token_ratio</th>\n",
       "      <th>lexical_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>structural_mention_density</th>\n",
       "      <th>structural_hashtag_density</th>\n",
       "      <th>structural_extra_spaces</th>\n",
       "      <th>structural_temporal_markers</th>\n",
       "      <th>syntactic_pos_tag_entropy</th>\n",
       "      <th>syntactic_pos_bigram_entropy</th>\n",
       "      <th>syntactic_avg_sentence_length</th>\n",
       "      <th>syntactic_subordinating_conj</th>\n",
       "      <th>syntactic_comma_ratio</th>\n",
       "      <th>syntactic_punct_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>\"The future is here: AI-powered virtual tutors...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>193.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.186646</td>\n",
       "      <td>3.272991</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>\"From predictive analytics that identify strug...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.133447</td>\n",
       "      <td>3.232776</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.161290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>\"Empower your classroom with AI-driven solutio...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>166.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>114.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.916567</td>\n",
       "      <td>2.999816</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.344828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>\"Let's debunk the myth - AI isn't replacing hu...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>237.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.235856</td>\n",
       "      <td>3.322242</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Ever wondered how AI can make teachers' lives ...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>188.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.251875</td>\n",
       "      <td>3.376443</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.235294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                               text  \\\n",
       "0       1.0  \"The future is here: AI-powered virtual tutors...   \n",
       "1       2.0  \"From predictive analytics that identify strug...   \n",
       "2       3.0  \"Empower your classroom with AI-driven solutio...   \n",
       "3       4.0  \"Let's debunk the myth - AI isn't replacing hu...   \n",
       "4       5.0  Ever wondered how AI can make teachers' lives ...   \n",
       "\n",
       "                                  topic  length      batch_timestamp  \\\n",
       "0  artificial intelligence in education   193.0  2025-09-07 11:05:21   \n",
       "1  artificial intelligence in education   192.0  2025-09-07 11:05:21   \n",
       "2  artificial intelligence in education   166.0  2025-09-07 11:05:21   \n",
       "3  artificial intelligence in education   237.0  2025-09-07 11:05:21   \n",
       "4  artificial intelligence in education   188.0  2025-09-07 11:05:21   \n",
       "\n",
       "   characters_remaining origin  model  lexical_type_token_ratio  \\\n",
       "0                  87.0    NaN    NaN                  0.933333   \n",
       "1                  88.0    NaN    NaN                  0.935484   \n",
       "2                 114.0    NaN    NaN                  0.896552   \n",
       "3                  43.0    NaN    NaN                  0.933333   \n",
       "4                  92.0    NaN    NaN                  1.000000   \n",
       "\n",
       "   lexical_word_count  ...  structural_mention_density  \\\n",
       "0                  30  ...                         0.0   \n",
       "1                  31  ...                         0.0   \n",
       "2                  29  ...                         0.0   \n",
       "3                  45  ...                         0.0   \n",
       "4                  34  ...                         0.0   \n",
       "\n",
       "   structural_hashtag_density  structural_extra_spaces  \\\n",
       "0                    0.033333                      0.0   \n",
       "1                    0.032258                      0.0   \n",
       "2                    0.000000                      0.0   \n",
       "3                    0.022222                      0.0   \n",
       "4                    0.029412                      0.0   \n",
       "\n",
       "   structural_temporal_markers  syntactic_pos_tag_entropy  \\\n",
       "0                          0.0                   2.186646   \n",
       "1                          0.0                   2.133447   \n",
       "2                          0.0                   1.916567   \n",
       "3                          0.0                   2.235856   \n",
       "4                          0.0                   2.251875   \n",
       "\n",
       "   syntactic_pos_bigram_entropy  syntactic_avg_sentence_length  \\\n",
       "0                      3.272991                       7.000000   \n",
       "1                      3.232776                      14.000000   \n",
       "2                      2.999816                       5.750000   \n",
       "3                      3.322242                      13.333333   \n",
       "4                      3.376443                       7.250000   \n",
       "\n",
       "   syntactic_subordinating_conj  syntactic_comma_ratio  syntactic_punct_ratio  \n",
       "0                           0.0               0.000000               0.433333  \n",
       "1                           0.0               0.032258               0.161290  \n",
       "2                           0.0               0.068966               0.344828  \n",
       "3                           0.0               0.044444               0.222222  \n",
       "4                           0.0               0.029412               0.235294  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntactic_features = [\n",
    "    fe.extract_syntactic_features(tokens)\n",
    "    for tokens in tqdm(processed_texts, desc=\"Extraindo features sintÃ¡ticas\")\n",
    "]\n",
    "df_syntactic = pd.DataFrame(syntactic_features)\n",
    "df_test = pd.concat([df_test, df_syntactic], axis=1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7296be24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>accessible</th>\n",
       "      <th>adaptive</th>\n",
       "      <th>ai</th>\n",
       "      <th>ai can</th>\n",
       "      <th>ai in</th>\n",
       "      <th>ai in education</th>\n",
       "      <th>ai is</th>\n",
       "      <th>ai is revolutionizing</th>\n",
       "      <th>ai powered</th>\n",
       "      <th>...</th>\n",
       "      <th>where</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>with ai</th>\n",
       "      <th>work</th>\n",
       "      <th>yes</th>\n",
       "      <th>you</th>\n",
       "      <th>you know</th>\n",
       "      <th>you ready</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   about  accessible  adaptive  ai  ai can  ai in  ai in education  ai is  \\\n",
       "0      0           0         0   1       0      0                0      0   \n",
       "1      0           0         0   1       0      0                0      0   \n",
       "2      0           0         1   1       0      0                0      0   \n",
       "3      0           0         0   1       0      0                0      0   \n",
       "4      0           0         0   1       1      0                0      0   \n",
       "\n",
       "   ai is revolutionizing  ai powered  ...  where  will  with  with ai  work  \\\n",
       "0                      0           1  ...      0     0     0        0     0   \n",
       "1                      0           0  ...      0     0     0        0     0   \n",
       "2                      0           0  ...      0     0     1        1     0   \n",
       "3                      0           0  ...      0     0     0        0     0   \n",
       "4                      0           0  ...      0     0     1        0     0   \n",
       "\n",
       "   yes  you  you know  you ready  your  \n",
       "0    0    0         0          0     0  \n",
       "1    0    0         0          0     0  \n",
       "2    0    0         0          0     1  \n",
       "3    0    0         0          0     0  \n",
       "4    0    0         0          0     0  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_df = fe.extract_ngrams_features(processed_texts, max_features=300)\n",
    "ngrams_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1939d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_421706/3577768971.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_combined['origin'] = df_combined['origin'].replace({'AI': 1, 'human': 0})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>length</th>\n",
       "      <th>batch_timestamp</th>\n",
       "      <th>characters_remaining</th>\n",
       "      <th>origin</th>\n",
       "      <th>model</th>\n",
       "      <th>lexical_type_token_ratio</th>\n",
       "      <th>lexical_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>where</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>with ai</th>\n",
       "      <th>work</th>\n",
       "      <th>yes</th>\n",
       "      <th>you</th>\n",
       "      <th>you know</th>\n",
       "      <th>you ready</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>\"The future is here: AI-powered virtual tutors...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>193.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>\"From predictive analytics that identify strug...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>\"Empower your classroom with AI-driven solutio...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>166.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>114.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>\"Let's debunk the myth - AI isn't replacing hu...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>237.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Ever wondered how AI can make teachers' lives ...</td>\n",
       "      <td>artificial intelligence in education</td>\n",
       "      <td>188.0</td>\n",
       "      <td>2025-09-07 11:05:21</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 336 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                               text  \\\n",
       "0       1.0  \"The future is here: AI-powered virtual tutors...   \n",
       "1       2.0  \"From predictive analytics that identify strug...   \n",
       "2       3.0  \"Empower your classroom with AI-driven solutio...   \n",
       "3       4.0  \"Let's debunk the myth - AI isn't replacing hu...   \n",
       "4       5.0  Ever wondered how AI can make teachers' lives ...   \n",
       "\n",
       "                                  topic  length      batch_timestamp  \\\n",
       "0  artificial intelligence in education   193.0  2025-09-07 11:05:21   \n",
       "1  artificial intelligence in education   192.0  2025-09-07 11:05:21   \n",
       "2  artificial intelligence in education   166.0  2025-09-07 11:05:21   \n",
       "3  artificial intelligence in education   237.0  2025-09-07 11:05:21   \n",
       "4  artificial intelligence in education   188.0  2025-09-07 11:05:21   \n",
       "\n",
       "   characters_remaining  origin  model  lexical_type_token_ratio  \\\n",
       "0                  87.0     NaN    NaN                  0.933333   \n",
       "1                  88.0     NaN    NaN                  0.935484   \n",
       "2                 114.0     NaN    NaN                  0.896552   \n",
       "3                  43.0     NaN    NaN                  0.933333   \n",
       "4                  92.0     NaN    NaN                  1.000000   \n",
       "\n",
       "   lexical_word_count  ...  where  will  with  with ai  work  yes  you  \\\n",
       "0                  30  ...      0     0     0        0     0    0    0   \n",
       "1                  31  ...      0     0     0        0     0    0    0   \n",
       "2                  29  ...      0     0     1        1     0    0    0   \n",
       "3                  45  ...      0     0     0        0     0    0    0   \n",
       "4                  34  ...      0     0     1        0     0    0    0   \n",
       "\n",
       "   you know  you ready  your  \n",
       "0         0          0     0  \n",
       "1         0          0     0  \n",
       "2         0          0     1  \n",
       "3         0          0     0  \n",
       "4         0          0     0  \n",
       "\n",
       "[5 rows x 336 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resetar os Ã­ndices de ambos os DataFrames\n",
    "df_test_reset = df_test.reset_index(drop=True)\n",
    "ngrams_df_reset = ngrams_df.reset_index(drop=True)\n",
    "\n",
    "# Agora concatenar\n",
    "df_combined = pd.concat([df_test_reset, ngrams_df_reset], axis=1)\n",
    "df_combined['origin'] = df_combined['origin'].replace({'AI': 1, 'human': 0})\n",
    "df_combined.fillna(0)\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c7b1eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>lexical_type_token_ratio</th>\n",
       "      <th>lexical_word_count</th>\n",
       "      <th>lexical_unique_words</th>\n",
       "      <th>lexical_avg_word_length</th>\n",
       "      <th>lexical_word_length_variance</th>\n",
       "      <th>lexical_stopword_ratio</th>\n",
       "      <th>stylistic_repeated_chars</th>\n",
       "      <th>stylistic_repeated_words</th>\n",
       "      <th>stylistic_exclamation_density</th>\n",
       "      <th>...</th>\n",
       "      <th>where</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>with ai</th>\n",
       "      <th>work</th>\n",
       "      <th>yes</th>\n",
       "      <th>you</th>\n",
       "      <th>you know</th>\n",
       "      <th>you ready</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>18.288889</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>5.387097</td>\n",
       "      <td>16.237253</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>5.137931</td>\n",
       "      <td>14.325803</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>45</td>\n",
       "      <td>42</td>\n",
       "      <td>4.511111</td>\n",
       "      <td>11.227654</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>4.735294</td>\n",
       "      <td>10.429931</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 329 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   origin  lexical_type_token_ratio  lexical_word_count  lexical_unique_words  \\\n",
       "0     NaN                  0.933333                  30                    28   \n",
       "1     NaN                  0.935484                  31                    29   \n",
       "2     NaN                  0.896552                  29                    26   \n",
       "3     NaN                  0.933333                  45                    42   \n",
       "4     NaN                  1.000000                  34                    34   \n",
       "\n",
       "   lexical_avg_word_length  lexical_word_length_variance  \\\n",
       "0                 5.666667                     18.288889   \n",
       "1                 5.387097                     16.237253   \n",
       "2                 5.137931                     14.325803   \n",
       "3                 4.511111                     11.227654   \n",
       "4                 4.735294                     10.429931   \n",
       "\n",
       "   lexical_stopword_ratio  stylistic_repeated_chars  stylistic_repeated_words  \\\n",
       "0                0.100000                         0                         0   \n",
       "1                0.129032                         0                         0   \n",
       "2                0.068966                         1                         0   \n",
       "3                0.088889                         0                         0   \n",
       "4                0.088235                         0                         0   \n",
       "\n",
       "   stylistic_exclamation_density  ...  where  will  with  with ai  work  yes  \\\n",
       "0                       0.066667  ...      0     0     0        0     0    0   \n",
       "1                       0.032258  ...      0     0     0        0     0    0   \n",
       "2                       0.068966  ...      0     0     1        1     0    0   \n",
       "3                       0.022222  ...      0     0     0        0     0    0   \n",
       "4                       0.029412  ...      0     0     1        0     0    0   \n",
       "\n",
       "   you  you know  you ready  your  \n",
       "0    0         0          0     0  \n",
       "1    0         0          0     0  \n",
       "2    0         0          0     1  \n",
       "3    0         0          0     0  \n",
       "4    0         0          0     0  \n",
       "\n",
       "[5 rows x 329 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined = df_combined.drop(columns=['topic', 'model', 'tweet_id', 'text', 'length', 'batch_timestamp', 'characters_remaining']) \n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8df3e364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>lexical_type_token_ratio</th>\n",
       "      <th>lexical_word_count</th>\n",
       "      <th>lexical_unique_words</th>\n",
       "      <th>lexical_avg_word_length</th>\n",
       "      <th>lexical_word_length_variance</th>\n",
       "      <th>lexical_stopword_ratio</th>\n",
       "      <th>stylistic_repeated_chars</th>\n",
       "      <th>stylistic_repeated_words</th>\n",
       "      <th>stylistic_exclamation_density</th>\n",
       "      <th>...</th>\n",
       "      <th>where</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>with ai</th>\n",
       "      <th>work</th>\n",
       "      <th>yes</th>\n",
       "      <th>you</th>\n",
       "      <th>you know</th>\n",
       "      <th>you ready</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>18.288889</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>5.387097</td>\n",
       "      <td>16.237253</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>5.137931</td>\n",
       "      <td>14.325803</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>45</td>\n",
       "      <td>42</td>\n",
       "      <td>4.511111</td>\n",
       "      <td>11.227654</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>4.735294</td>\n",
       "      <td>10.429931</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 329 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   origin  lexical_type_token_ratio  lexical_word_count  lexical_unique_words  \\\n",
       "0     1.0                  0.933333                  30                    28   \n",
       "1     1.0                  0.935484                  31                    29   \n",
       "2     1.0                  0.896552                  29                    26   \n",
       "3     1.0                  0.933333                  45                    42   \n",
       "4     1.0                  1.000000                  34                    34   \n",
       "\n",
       "   lexical_avg_word_length  lexical_word_length_variance  \\\n",
       "0                 5.666667                     18.288889   \n",
       "1                 5.387097                     16.237253   \n",
       "2                 5.137931                     14.325803   \n",
       "3                 4.511111                     11.227654   \n",
       "4                 4.735294                     10.429931   \n",
       "\n",
       "   lexical_stopword_ratio  stylistic_repeated_chars  stylistic_repeated_words  \\\n",
       "0                0.100000                         0                         0   \n",
       "1                0.129032                         0                         0   \n",
       "2                0.068966                         1                         0   \n",
       "3                0.088889                         0                         0   \n",
       "4                0.088235                         0                         0   \n",
       "\n",
       "   stylistic_exclamation_density  ...  where  will  with  with ai  work  yes  \\\n",
       "0                       0.066667  ...      0     0     0        0     0    0   \n",
       "1                       0.032258  ...      0     0     0        0     0    0   \n",
       "2                       0.068966  ...      0     0     1        1     0    0   \n",
       "3                       0.022222  ...      0     0     0        0     0    0   \n",
       "4                       0.029412  ...      0     0     1        0     0    0   \n",
       "\n",
       "   you  you know  you ready  your  \n",
       "0    0         0          0     0  \n",
       "1    0         0          0     0  \n",
       "2    0         0          0     1  \n",
       "3    0         0          0     0  \n",
       "4    0         0          0     0  \n",
       "\n",
       "[5 rows x 329 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined['origin'] = df_combined['origin'].fillna(1)\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aeb3e33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv(\"/home/tammy.kojima/Authorship-attribution/df_pronto/df_mistral_com_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "decfe03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>lexical_type_token_ratio</th>\n",
       "      <th>lexical_word_count</th>\n",
       "      <th>lexical_unique_words</th>\n",
       "      <th>lexical_avg_word_length</th>\n",
       "      <th>lexical_word_length_variance</th>\n",
       "      <th>lexical_stopword_ratio</th>\n",
       "      <th>stylistic_repeated_chars</th>\n",
       "      <th>stylistic_repeated_words</th>\n",
       "      <th>stylistic_exclamation_density</th>\n",
       "      <th>...</th>\n",
       "      <th>chatgpt_structured_output</th>\n",
       "      <th>chatgpt_overly_polite</th>\n",
       "      <th>chatgpt_disclaimer_density</th>\n",
       "      <th>chatgpt_assistant_patterns</th>\n",
       "      <th>mistral_self_ref</th>\n",
       "      <th>mistral_structured_density</th>\n",
       "      <th>mistral_technical_jargon</th>\n",
       "      <th>mistral_non_english_density</th>\n",
       "      <th>mistral_step_reasoning</th>\n",
       "      <th>mistral_low_ethical_disclaimers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>18.288889</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>5.387097</td>\n",
       "      <td>16.237253</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>5.137931</td>\n",
       "      <td>14.325803</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>45</td>\n",
       "      <td>42</td>\n",
       "      <td>4.511111</td>\n",
       "      <td>11.227654</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>4.735294</td>\n",
       "      <td>10.429931</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 356 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   origin  lexical_type_token_ratio  lexical_word_count  lexical_unique_words  \\\n",
       "0     1.0                  0.933333                  30                    28   \n",
       "1     1.0                  0.935484                  31                    29   \n",
       "2     1.0                  0.896552                  29                    26   \n",
       "3     1.0                  0.933333                  45                    42   \n",
       "4     1.0                  1.000000                  34                    34   \n",
       "\n",
       "   lexical_avg_word_length  lexical_word_length_variance  \\\n",
       "0                 5.666667                     18.288889   \n",
       "1                 5.387097                     16.237253   \n",
       "2                 5.137931                     14.325803   \n",
       "3                 4.511111                     11.227654   \n",
       "4                 4.735294                     10.429931   \n",
       "\n",
       "   lexical_stopword_ratio  stylistic_repeated_chars  stylistic_repeated_words  \\\n",
       "0                0.100000                         0                         0   \n",
       "1                0.129032                         0                         0   \n",
       "2                0.068966                         1                         0   \n",
       "3                0.088889                         0                         0   \n",
       "4                0.088235                         0                         0   \n",
       "\n",
       "   stylistic_exclamation_density  ...  chatgpt_structured_output  \\\n",
       "0                       0.066667  ...                   0.000000   \n",
       "1                       0.032258  ...                   0.000000   \n",
       "2                       0.068966  ...                   0.000000   \n",
       "3                       0.022222  ...                   0.022222   \n",
       "4                       0.029412  ...                   0.000000   \n",
       "\n",
       "   chatgpt_overly_polite  chatgpt_disclaimer_density  \\\n",
       "0                    0.0                         0.0   \n",
       "1                    0.0                         0.0   \n",
       "2                    0.0                         0.0   \n",
       "3                    0.0                         0.0   \n",
       "4                    0.0                         0.0   \n",
       "\n",
       "   chatgpt_assistant_patterns  mistral_self_ref  mistral_structured_density  \\\n",
       "0                         0.0               0.0                    0.000000   \n",
       "1                         0.0               0.0                    0.000000   \n",
       "2                         0.0               0.0                    0.000000   \n",
       "3                         0.0               0.0                    0.022222   \n",
       "4                         0.0               0.0                    0.000000   \n",
       "\n",
       "   mistral_technical_jargon  mistral_non_english_density  \\\n",
       "0                       0.0                          0.0   \n",
       "1                       0.0                          0.0   \n",
       "2                       0.0                          0.0   \n",
       "3                       0.0                          0.0   \n",
       "4                       0.0                          0.0   \n",
       "\n",
       "   mistral_step_reasoning  mistral_low_ethical_disclaimers  \n",
       "0                     0.0                              0.0  \n",
       "1                     0.0                              0.0  \n",
       "2                     0.0                              0.0  \n",
       "3                     0.0                              0.0  \n",
       "4                     0.0                              0.0  \n",
       "\n",
       "[5 rows x 356 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined = pd.read_csv('/home/tammy.kojima/Authorship-attribution/df_pronto/df_mistral_com_features.csv')\n",
    "X_new_features = fe.extract_features_batch(textos, processed_texts = processed_texts)\n",
    "df_features = pd.DataFrame(X_new_features)\n",
    "df_combined = pd.concat([df_combined, df_features], axis=1)\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ae55006",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv('/home/tammy.kojima/Authorship-attribution/df_pronto/df_mistral_com_features2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
